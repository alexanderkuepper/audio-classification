{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow_io as tfio\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Data Loading Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Tensorflow Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('train_data/train/')\n",
    "test_dir = Path('train_data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(value):\n",
    "    if value == \"capuchinbird\":\n",
    "        return tf.one_hot(0,5)\n",
    "    if value == \"cricket\":\n",
    "        return tf.one_hot(1,5)\n",
    "    if value == \"robin\":\n",
    "        return tf.one_hot(2,5)\n",
    "    if value == \"sparrow\":\n",
    "        return tf.one_hot(3,5)   \n",
    "    if value == \"owl\":\n",
    "        return tf.one_hot(4,5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = pd.Series(list(train_dir.glob(r'**/*.wav'))).astype(str)\n",
    "train_animals = pd.Series(train_filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1])).astype(str)\n",
    "\n",
    "train_lables = train_animals.map(transform).to_list()\n",
    "\n",
    "train = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(train_filepaths), tf.data.Dataset.from_tensor_slices(train_lables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepaths = pd.Series(list(train_dir.glob(r'**/*.wav'))).astype(str)\n",
    "test_animals = pd.Series(test_filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1])).astype(str)\n",
    "\n",
    "test_lables = test_animals.map(transform).to_list()\n",
    "\n",
    "test = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(test_filepaths), tf.data.Dataset.from_tensor_slices(test_lables)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Preprocessing Function to Convert to Spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    \n",
    "    return spectrogram, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Training and Testing Partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "train = train.map(preprocess)\n",
    "train = train.cache()\n",
    "train = train.shuffle(buffer_size=1000)\n",
    "train = train.batch(16)\n",
    "train = train.prefetch(8)\n",
    "\n",
    "test = test.map(preprocess)\n",
    "test = test.cache()\n",
    "test = test.shuffle(buffer_size=1000)\n",
    "test = test.batch(16)\n",
    "test = test.prefetch(8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 1489, 255, 16)     160       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1487, 253, 16)     2320      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6019376)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               770480256 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 770,483,381\n",
      "Trainable params: 770,483,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "22/22 [==============================] - 116s 5s/step - loss: 6.4664 - recall_1: 0.8338 - precision_1: 0.8754 - val_loss: 0.1394 - val_recall_1: 0.9852 - val_precision_1: 0.9881\n",
      "Epoch 2/4\n",
      "22/22 [==============================] - 107s 5s/step - loss: 0.1056 - recall_1: 0.9733 - precision_1: 0.9762 - val_loss: 0.0300 - val_recall_1: 0.9881 - val_precision_1: 0.9881\n",
      "Epoch 3/4\n",
      "22/22 [==============================] - 107s 5s/step - loss: 0.0484 - recall_1: 0.9911 - precision_1: 0.9911 - val_loss: 0.0018 - val_recall_1: 1.0000 - val_precision_1: 1.0000\n",
      "Epoch 4/4\n",
      "22/22 [==============================] - 112s 5s/step - loss: 0.0247 - recall_1: 0.9881 - precision_1: 0.9881 - val_loss: 0.0129 - val_recall_1: 0.9941 - val_precision_1: 0.9941\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model with a Single Clip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "output = list()\n",
    "for y in yhat:\n",
    "    if y[0] > 0.5:\n",
    "        y[0] = 1\n",
    "    else:\n",
    "        y[0] = 0\n",
    "    if y[1] > 0.5:\n",
    "        y[1] = 1\n",
    "    else:\n",
    "        y[1] = 0\n",
    "    if y[2] > 0.5:\n",
    "        y[2] = 1\n",
    "    else:\n",
    "        y[2] = 0\n",
    "    if y[3] > 0.5:\n",
    "        y[3] = 1\n",
    "    else:\n",
    "        y[3] = 0\n",
    "    if y[4] > 0.5:\n",
    "        y[4] = 1\n",
    "    else:\n",
    "        y[4] = 0\n",
    "    output.append(list(y))\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c1d87ea85a731d0848cf4e607dbb57360506d747d84c6cb1b30d4e34e6c1fb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
